=============================================
Лабораторная работа №4: Workqueue и таймеры в ядре Linux  
=============================================

Структура директории (Directory structure)
-----

+-------------------+----------------------------------+ 
| Folder and files  | description                      |
+===================+==================================+ 
|        scr        | The source code of the lab work  |
+-------------------+----------------------------------+ 
|       Makefile    | File to compile project          | 
+-------------------+----------------------------------+ 
|       README.rst  | Lab work report                  |
+-------------------+----------------------------------+


Цели и задание
-----
Изученение принципов работы ``workqueue``, ``shared workqueue`` и таймеров в ядре Linux. 
Механизмы синхронизации в ядре. 

Задание на четвертую лабораторную:

- Реализовать два потока, запустить таймер и ворк в shared workqueue

- При срабатывании таймера проверить текущее значение jiffies, если оно кратно 11 – остановить поток 1, иначе – таймер должен перезапустить себя через 17 jiffies

- Внутри ворка проверить текущее значение jiffies, если оно кратно 11 – остановить поток 2, иначе – ворк должен уснуть на 17 jiffies и перезапустить себя

- Добавить два связных списка, в которые аллоцировать и добавлять элементы со значениями jiffies, которые не привели к завершению потоков 1 и 2. Получается связь таймер - список 1 - поток 1. И ворк - список 2 - поток 2

- При выходе из потоков распечатывать списки

- Внутри ворка и таймера использовать правильные аллокации для новых элементов списка, правильную синхронизацию работы со списком

- Предусмотреть, что пользователь может выгрузить модуль до отработки всех таймеров и ворков


Теоретическая база работы 
-----

Очередь отложенных действий (``workqueue``) — это интерфейс для создания потоков ядра, 
выполняющих действия, которые кем-то были поставлены в очередь. Эти потоки ядра называются рабочими потоками (worker threads).
Очереди действий позволяют создавать специальные рабочие потоки ядра для того, чтобы выполнять отложенные действия. 
Кроме того, в подсистеме очередей отложенных действий предусмотрен специальный стандартный рабочий поток, 
выполняющий нужную работу. 
Тем не менее ничто не запрещает коду ядра создавать собственные рабочие потоки. 
Это может понадобиться, если в рабочем потоке выполняется большое количество вычислительных операций. 
Для операций, интенсивно использующих центральный процессор или критичных ко времени выполнения, 
также имеет смысл создавать отдельные рабочие потоки. В результате будет уменьшена нагрузка на стандартные рабочие
потоки и устранена проблема нехватки ресурсов для выполнения остальных отложенных действий.
Рабочие потоки представляются с помощью структуры ``workqueue_struct``. Эта структура определена в файле ``kernel/workqueue.c``.
В ней содержится массив структур ``cpu_workqueue_struct``, каждый элемент которого соответствует одному процессору в системе.
Поскольку рабочие потоки создаются для каждого процессора в системе, для каждого рабочего потока, 
работающего на каждом процессоре машины, существует такая структура.
Все рабочие потоки реализованы как обычные потоки ядра, которые выполняют функцию ``worker_thread()``. 
После начальной инициализации эта функция входит в бесконечный цикл и переходит в состояние ожидания.
Когда какая-либо работа ставится в очередь, поток активизируется и выполняет ее.
Когда в очереди не остается работы, которую нужно выполнить, поток снова переходит в состояние ожидания. 
Каждое действие представлено с помощью структуры ``work_struct``, определенной в файле ``<linux/workqueue.h>``.
Эти структуры объединены в связанный список, по одному списку на каждый тип очереди для каждого процессора. 
Например, для каждого процессора существует список отложенных действий, которые выполняются стандартными рабочими потоками.
При активизации рабочий поток начинает выполнять все действия, которые находятся в его списке. 
После завершения работы он удаляет соответствующие структуры ``work_struct`` из связанного списка. 
Когда список становится пустым, поток переходит в состояние ожидания.

В бесконечном цикле функция ``worker_thread()`` обрабатывает каждый элемент связанного списка отложенных действий и 
запускает функцию, указатель которой находится в поле func структуры ``workqueue_struct``. 
При этом выполняются перечисленные действия:

1. Если список не пустой, выбирается следующий элемент списка. 
2. Из поля func выбирается указатель на функцию, которую необходимо вызвать, а из поля data — аргумент этой функции. 
3. Текущий элемент удаляется из списка и сбрасывается бит ожидания в его структуре. 
4. Вызывается сама функция.
5. Перечисленные выше действия повторяются.

Для инициализации ``work`` во время выполнения кода, необходимо использовать макрос ``INIT_WORK(struct work_struct *work, void (*func)(void *), void *data);``
Куда передать указатель на  экземляр структуры ``work_struct``, указатель на функцию-обработчик и аргумент этой функции. 
В случае необходимости инициализации ``work``, который необходимо запланировать на выполнение не сразу, а с необходимой задержкой,
можно использовать макрос ``INIT_DELAYED_WORK( work, func )`` или ``INIT_DELAYED_WORK_DEFERRABLE( work, func )``. 
Иногда требуется выполнить отложенное действие не немедленно, а с некоторой задержкой. 
Для этого следует запланировать это действие в заданный момент времени в будущем c помощью
функции ``schedule_delayed_work(&work, delay)``. В этом случае действие, представленное структурой ``work_struct``, 
с адресом &work, не будет выполнено, пока не пройдет заданное в параметре delay количество импульсов таймера. 
Отложенные действия, поставленные в очередь, выполняются, когда рабочий поток в следующий раз будет выведен из состояния 
ожидания. Иногда нужно гарантировать, чтобы перед началом некоторой работы заданный пакет отложенных действий завершил 
свое выполнение. Очевидно, например, что перед выгрузкой из памяти загружаемых модулей ядра все установленные ими 
отложенные действия должны завершиться. В других местах ядра также может понадобиться гарантировать, 
что не будет конфликтов из-за доступа к системным ресурсам, возникающих из-за ожидающих выполнения отложенных действий. 
Для выполнения описанных выше действий предусмотрена функция ``flush_ scheduled_work``, 
ожидающая, пока заданная очередь отложенных действий не будет очищена.
Эта функция не аннулирует никаких отложенных действий, запланированных на выполнение с задержкой. 
Любые отложенные действия, запланированные на выполнение с помощью функции ``schedule_delayed_work()``
и интервал времени задержки которых еще не истек, не аннулируются с помощью вызова функции flush_scheduled_work(). 
Для отмены отложенных действий с задержками следует использовать ``cancel_delayed_work(struct work_struct *work)``. 
Эта функция отменяет отложенное действие, которое связано с данной структурой ``work_struct``, 
если оно запланировано на выполнение.

Отложенное планирование ``work``, как было сказано выше, реализуется с помощью таймеров и содейственных ему механизмов. Однако,
помимо этого таймеры - это отдельный механизм выполнения действий с привязкой ко времени выполнения. 
таймеры ядра, необходимы для управления ходом времени в ядре. В коде ядра часто необходимо отложить выполнение 
некоторых функций на более позднее время. Именно на такой промежуток времени, который может быть слишком большим для
выполнения данной работы с механизмом прерываний нижних половин. Таймеры представляются в ядре с помощью структуры 
``timer_list``, которая определена в файле ``<linux/timer.h>``. 
Перед использованием таймера его нужно объявить так - ``struct timer_list timer``.
Проинициализировать таймер можно с помощью макроса ``timer_setup(timer, callback, flags)``, где передать указатель на ранее
обьявленый таймер, функцию обработчик и дополнительные флаги.
Прототип обработчика таймера имеет следующий вид ``void timer_handler(struct timer_list *tim)``.
Иногда может потребоваться изменить момент времени срабатывания таймера, который уже запущен. 
Для этого в ядре предусмотрена функция ``mod_timer()``. 
Функцию ``mod_timer()`` можно также использовать в случае, если таймер уже проинициализирован, но еще не запущен. 
Если таймер не активен, то эта функция ``mod_timer()`` запускает его. Функция возвращает значение 0, если таймер был незапущен-ный,
и значение 1, если таймер был уже запущен. В любом случае перед возвратом из функции ``mod_timer()`` таймер будет запущен 
и настроен на новое время срабатывания. Если нужно остановить таймер до момента его срабатывания, 
используется функция ``del_timer()``.
В ядре функции-обработчики таймеров запускаются в виде отложенного прерывания (``softirqs``) после завершения обработки 
прерывания от таймера. Все это происходит в контексте нижней половины обработчика прерывания. Поэтому, стоит учитывать, что
использование операций склонных ко сну могут привести к непредвиденным ошибкам.

Важной темой в рамках выполения данной работы, стоит упомянуть про механизмы синхронизации работы с операциями чтения и записи,
которые свойствены в том числе и для работы со списком. Одной из стратегий синхронизаций в ядре является ``Read-copy update (RCU)``.
``RCU`` обеспечивает улучшения масштабируемости, позволяя выполнять чтение одновременно с обновлениями. 
В отличие от обычных примитивов блокировки, которые обеспечивают взаимное исключение между параллельными потоками 
независимо от того, являются ли они читателями или программами обновления, или с блокировками чтения-записи, 
которые разрешают параллельные чтения, но не при наличии обновлений, ``RCU`` поддерживает параллелизм между одним 
средством обновления и несколькими устройствами чтения , ``RCU`` обеспечивает согласованность операций чтения,
поддерживая несколько версий объектов и обеспечивая, чтобы они не освобождались до тех пор, 
пока не завершатся все существующие ранее критические разделы на стороне чтения. 
RCU определяет и использует эффективные и масштабируемые механизмы для публикации и чтения новых версий объекта,
а также для отсрочки сбора старых версий. Эти механизмы распределяют работу между путями чтения и обновления таким образом,
чтобы сделать пути чтения чрезвычайно быстрыми. В некоторых случаях (не выгружаемые ядра) примитивы ``RCU`` на стороне чтения
имеют нулевые накладные расходы. Эта стратегия работает более оптимально нежеди ``seqlock``, которая также имеет возможность 
одновременной работы программы читателей и программ обновления, но во время работы одной, другая - не может выполнять никакую работу.
Одним из лучших применений ``RCU`` является защита связанных списков ориентированыых для чтения. 
Лучшими приложениями являются случаи, если бы использовалась блокировка чтения-записи, 
блокировка на стороне чтения была бы снята, прежде чем предпринимать какие-либо действия, основанные на результатах поиска.
Необходимые примитивы для работы ``RCU`` были использованы при выполении данной работы и будут описаны в разделе Выполнение.


Выполнение  
-----
В директории ``src`` данной лабораторной работы находится исходный файл модуля ядра ``workmod.c`` 
с результатом заданий в рамках данной работы. Проведём небольшой анализ исходного кода:

#. Проведена инициализация структуры пользовательского типа ``k_list``. В структуре присутствует переменная ``count_val``,
   которая будет иметь в себе значение jiffies из обработчиков work и таймера. ``struct rcu_head rcu`` необходим 
   для работы со сценарием синхронизации ``RCU``.
   ``test_list`` типа ``list_head`` внедряет механизм связного списка в структура пользователя. ``LIST_HEAD`` 
   инициализирует указатель на два списка (по одному на каждый поток). Потоки создаються аналогично к предыдущей работе.
   Также, задекларирована переменная для спин-блокировки, таймера и ворка.  
   
   
   .. code-block:: C

      struct k_list {

        struct list_head test_list;
        struct rcu_head rcu;
        long long count_val;

      };
      
      ....
      
      LIST_HEAD(head_first_list);
      LIST_HEAD(head_second_list); 
      ....
      static DEFINE_SPINLOCK(rcu_lock);
      struct timer_list timer;
      struct delayed_work work; 


#. Дополнительно обьявлена структура с перменными типа битового поля для индикации текущего состояния 
   работы потоков (1 - поток активен, 0 - поток закончил работу). Общий фрагмент кода наведен ниже:
      
      .. code-block:: C
      
          struct flags {

          unsigned first_thread_active:1;
          unsigned second_thread_active:1;

          };

          struct flags flags_stat = {0};
          

#. Само обьявление и определение функций потоков наведено ниже. Они не выполняют полезную работу, пока не придёт сигнал от 
   ворка или таймера про окончание их работы. Но перед окончанием, они выведут списки ворка и таймера.
   
    .. code-block:: C
    
          static int first_thread_func(void *argument)
          {

            while (flags_stat.first_thread_active) {

               schedule();
              }


            listtest_show_list(&head_first_list);

            return 0;
          }
          
           ....

          static int second_thread_func(void *argument)
          {

            while (!kthread_should_stop()) {

               schedule();
              }

            listtest_show_list(&head_second_list);
            flags_stat.second_thread_active = 0;

            return 0;

          }

#. Обьявлены и реализованы обработчики ворка и таймера, которые выполняют схожую функцию по условиям задания.
   Здесь начинают применяться ``RCU``-примитивы, такой как ``list_add_rcu``, обеспечивающий синхронизацию работы 
   со списком в контексте чтение-обновление. Также применена для этих целей спин-блокировка Общий листинг наведен ниже: 
   
    .. code-block:: C
    
        void work_handler(struct work_struct *arg)
        {

          if ((jiffies%11) == 0) {

            kthread_stop(thread_t[1]);
            flags_stat.second_thread_active = 0;		

          } else {

            struct k_list *data;
            if (!(data = kmalloc(sizeof(struct k_list), GFP_KERNEL))) {
              printk(KERN_ERR "Allocation error of node");
            } else {
              data->count_val = jiffies;
              spin_lock(&rcu_lock);
              list_add_rcu(&data->test_list, &head_second_list);
              spin_unlock(&rcu_lock);
              schedule_delayed_work(&work, 17);
            }
          }
        }

       .....

        void timer_handler(struct timer_list *tim)
        {

          if ((jiffies%11) == 0) {

            flags_stat.first_thread_active = 0;			

          } else {

            struct k_list *data;
            if (!(data = kmalloc(sizeof(struct k_list), GFP_KERNEL))) {
              printk(KERN_ERR "Allocation error of node");
            } else {
              data->count_val = jiffies;
              spin_lock(&rcu_lock);
              list_add_rcu(&data->test_list, &head_first_list);
              spin_unlock(&rcu_lock);
              mod_timer(&timer, jiffies + 17);
            }

          }
        }

#. На конец рассмотрим функции вывода и удаления списка, который синхронизированы в контексте ``RCU``-стратегии.
   При входе в критическую секцию выставляется ``rcu_read_lock()``.  Любая защищенная ``RCU`` структура данных, доступ к 
   которой осуществляется во время критической секции на стороне чтения ``RCU``, гарантированно останется невостребованной 
   в течение всей продолжительности этой критической секции. Подсчет ссылок может использоваться вместе с RCU для поддержки 
   долгосрочных ссылок на структуры данных. Также, для обхода списка использован примитив ``list_for_each_entry_rcu``, который
   не приведет к segfault при одновременном выполнении с ``list_add_rcu()``
   В случае удаления достаточно удерживать спин-блокировку. 

    .. code-block:: C

      static void listtest_show_list(struct list_head *a_list)
      {

              struct list_head *listptr;
              struct k_list *entry;
        printk(KERN_ALERT "Show_list\n");

        rcu_read_lock();

        list_for_each_entry_rcu(entry, a_list, test_list) {
          printk(KERN_INFO "Jiffies =  %lld ", entry->count_val);
        }

        rcu_read_unlock();
      }

      ....

      void delete_list(struct list_head *a_list)
      {

        if (NULL == a_list)
          return;

        struct k_list *entry;
              struct list_head *del_node, *tmp;

        spin_lock(&rcu_lock);
        list_for_each_safe(del_node, tmp, a_list)
        {
          entry = list_entry(del_node, struct k_list, test_list);
          list_del(del_node);
          kfree(entry);  
        }
        spin_unlock(&rcu_lock);

      }
          
Сборка модуля и тестирование 
-----          
Процесс сборки и запуска проекта следующий:

#. Для автоматизированной сборки используется Kbuild. С помощью команды ``make`` производиться сборка и компиляция 
   модуля. Для кросс-компиляции можно также указать архитектуру, компилятор и директорию исходников.  
   Например, компиляции для ARMv7 для SoC ``Zynq-7000``: ``make ARCH=arm CROSS_COMPILE=arm-xilinx-linux-gnueabihf- KBUILDDIR=<path_to_linux_src>/linux-xlnx-xilinx-v2017.4/``.
#. Для добавления модуля в ядро нужно использовать ``sudo insmod workmod.ko``. 
#. Для просмотра логов ядра можно использовать ``dmesg -k | tail -20``.   
#. Для удаления модуля нужно использовать ``sudo rmmod workmod.ko``.
#. Для удаления резульатов сборки можно использовать ``make clean`` и ``make tidy``.

Анализ полученных результатов 
-----   
Было проведено тестирование модуля модуля и получен следующий лог ядра:

.. code-block:: C

    [ 6010.903126] Show_list
    [ 6010.903127] Jiffies =  4296680513 
    [ 6010.903127] Jiffies =  4296680495 
    [ 6010.903127] Jiffies =  4296680477 
    [ 6010.903128] Jiffies =  4296680459 
    [ 6010.903128] Jiffies =  4296680441 
    [ 6010.903129] Jiffies =  4296680423 
    [ 6010.903129] Jiffies =  4296680405 
    [ 6011.013118] Show_list
    [ 6011.013118] Jiffies =  4296680546 
    [ 6011.013119] Jiffies =  4296680528 
    [ 6011.013119] Jiffies =  4296680510 
    [ 6011.013119] Jiffies =  4296680492 
    [ 6011.013120] Jiffies =  4296680474 
    [ 6011.013120] Jiffies =  4296680456 
    [ 6011.013120] Jiffies =  4296680438 
    [ 6011.013121] Jiffies =  4296680420 
    [ 6018.629015] Module exit


Как можно увидеть, выводяться два списка, вывод которых вызывается после сигнала на окончание работы потока от таймера или ворка.
Напомню, что это происходит после проверки в ворке или таймере кратность значения ``jiffies`` числу 11. В ином случае, ворк и таймер
планируються на выполнение через ``17 jiffies``. Механизмы планирования ворка и таймера не гарантирует выполение обработчиков строго
после указанного периода, они лишь гарантируют выполение обработчика не раньше указанного периода, но и как можно быстрее после него. 
Из-за этого иногда могут появляться разница шага значения ``jiffies`` в элементах списков больше чем ожидаемая. 

