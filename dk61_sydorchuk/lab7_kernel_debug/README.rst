=============================================
Лабораторная работа №7: Отладка ядра    
=============================================

Структура директории (Directory structure)
-----

+-------------------+----------------------------------+ 
| Folder and files  | description                      |
+===================+==================================+ 
|        scr        | The source code of the lab work  |
+-------------------+----------------------------------+ 
|       Makefile    | File to compile project          | 
+-------------------+----------------------------------+ 
|       README.rst  | Lab work report                  |
+-------------------+----------------------------------+


Цели и задание
-----
  
– разобраться с debugfs;

– добавить к предыдущей лабораторной возможность читать и писать в буфферы с помощью debugfs (при открытии файла и аллокации буффера, в debugfs создается entry с именем в виде адреса file, содержимым в качестве blob);

– разобраться с отладкой модулей ядра средствами GDB;

– попробовать отлаживать модуль hive средствами gdb на ядре, запущенном в qemu;

– попробовать положить ядро, записать crash dump и затем исследовать его с помощью crash (вместо положить можно использовать sysrq);



Возможности отладки в ядре
-----

Существует несколько параметров конфигурации, которые помогают в отладке и тестировании кода ядра и 
включаются во время компиляции. Эти параметры собраны в виде меню ``Kernel hacking`` редактора конфигурации ядра и зависят
от параметра ``CONFIG_DEBUG_KERNEL``.

**DebugFS**

``Debugfs`` сделан для разработчиков ядра как простой способ сделать информацию доступной для пользователя. 
В отличие от ``/proc``, который предназначен только для информации о процессе, или ``sysfs``, который имеет строгие правила 
«одно значение на файл», debugfs вообще не имеет правил. Разработчики могут поместить любую информацию, которую просматривать с пространства 
пользователя. Файловая система ``debugfs`` также не предназначена для использования в качестве стабильного ABI для пользовательского 
пространства. Фактически по заявлению разработчиков, нет никаких ограничений стабильности на экспортируемые елементы. 
Но в реальном мире оказалось, что этот способ отладки не так просто использовать, несмотря на вариативность ``API``. 
Подробнее об этом и про сагу со стабильным ABI ядра можно ознакомиться `здесь <https://lwn.net/Articles/309298/>`__  
Ознакомимся подробнее с API. ``Debugfs`` позволяет создавать разные типы обьектов для отслеживания их в пространстве пользователя.
Различные функции числовых, булевых значений или фрагментов памяти (в основном текстовых):

    .. code-block:: C
      
      struct dentry *debugfs_create_u8(const char *name, umode_t mode,
					     struct dentry *parent, u8 *value);
      struct dentry *debugfs_create_u16(const char *name, umode_t mode,
					      struct dentry *parent, u16 *value);
      struct dentry *debugfs_create_u32(const char *name, umode_t mode,
					      struct dentry *parent, u32 *value);
      struct dentry *debugfs_create_u64(const char *name, umode_t mode,
					      struct dentry *parent, u64 *value);
      struct dentry *debugfs_create_bool(const char *name, umode_t mode,
                                     struct dentry *parent, bool *value);
      struct dentry *debugfs_create_blob(const char *name, umode_t mode,
			       struct dentry *parent, struct debugfs_blob_wrapper *blob);

Последняя функция отвечает за отображение отдельных фрагментов памяти, которые указаны в структуре ``debugfs_blob_wrapper``:

   .. code-block:: C
   
     struct debugfs_blob_wrapper {
        void *data;
        unsigned long size;
     };

Для числовых и булевых екземпляров в директории ``debugfs`` важно понимать то, что они доступны для чтения и записи, а элементы 
``blob`` доступны только для чтения. 

Перед началом использования стоит проинициализировать директорию с местом нахождения исследуемых значений:

      .. code-block:: C

        struct dentry *debugfs_create_dir(const char *name, struct dentry *parent);
 
В поле ``parent`` можно указать ``NULL``, так как это верхний уровень иерархии в директории ``debugfs``, но именно возвращаемый
указатель станет главным узлом, к которому стоит привязывать все элементы или файлы. Касаемо файлов, то их тоже можно создавать 
для отладки этим способом, причём также можно указывать отдельные операции для этого файла по аналогии с драйверами. Создавать 
файл можно ч помощью следующей функции:
 
    .. code-block:: C
     
       struct dentry *debugfs_create_file(const char *name, umode_t mode,
                       struct dentry *parent, void *data,
                       const struct file_operations *fops);
 
``fops`` должен содержать указатель на структуру ``file_operations`` с операциями для этого файла. 

Просматривать результат необходимо в директории ``/sys/kernel/debug``, зачастую она подмонтирована автоматически. В ином случае
это необходимо сделать вручную.

**GDB**

Для того что бы провести отладку в работающее ядро, можно использовать стандартный отладчик GNU. 
Запуск отладчика для работы с ядром почти ничем не отличается от отладки запущенного процесса:

``gdb vmlinux /proc/kcore``

Файл ``vmlinux`` — это разархивированный исполняемый образ ядра, который хранится в корне каталога исходных кодов, 
где выполнялась сборка. Сжатые файлы ``zImage`` и ``bzImage`` использовать нельзя.
Необязательный параметр ``/proc/kcore`` играет роль файла core и позволяет отладчику 
просмотреть память выполняющегося ядра. Чтобы иметь возможность прочитать этот файл, 
необходимо иметь права пользователя root.
Если при компиляции ядра был указан флаг ``-g`` (его необходимо добавить к значению
переменной CFLAGS в файле Makefile построения ядра), то отладчик gdb сможет вы-
вести намного больше информации. Например, можно выводить дампы структур данных
и переходить по значению указателя.


**KGDB**

Отладчик ``kgdb`` — это заплата ядра, которая позволяет с помощью отладчика ``gdb``
выполнять отладку ядра на удаленном терминале, подключенном к последовательному
порту компьютера. Для этого потребуются два компьютера. На первом запускается ядро
с ``kgdb``. На втором, подключенном к последовательному порту первого через запускается терминал, 
в окне которой работает отладчик ``gdb``. Благодаря заплате ``kgdb`` становится полностью доступен весь набор средств
отладчика ``gdb``: чтение и запись любых переменных, установка точек останова, установ-
ка точек слежения (``breakpoints``), пошаговое исполнение и т.д. Специальные версии
kgdb даже позволяют вызывать функции.

**Crash Dump на основе kexec**

``kdump`` - это особенный механиз ядра Linux, который создает аварийные дампы в случае сбоя ядра. 
При запуске kdump экспортирует образ памяти (также известный как vmcore), который можно проанализировать 
для целей отладки и определения причины сбоя. Дамп-образ основной памяти, экспортируемый как объект 
исполняемого формата (ELF), может быть доступен либо напрямую через
``/proc/vmcore`` во время обработки сбоя ядра, либо он может автоматически сохраняться в локально доступную 
файловой систему. Механизм основан на ``kexec``, который как раз позволяет запускать ядра поверх работающего пропускаю привычные 
этапы загрузки. 

Для работы необходимо дополнительно иметь место для специального ядра (ядро захвата дампа), которое будет производить захват 
дампа после краха основного. Содержимое оперативной памяти (RAM) сохраняется при загрузке и запуске ядра захвата дампа путем 
предварительного резервирования небольшого объема оперативной памяти, в которую предварительно загружено ядро 
захвата дампа. Никто из пользователей оперативной памяти не может использовать это пространство. 
Этот зарезервированный объем ОЗУ используется исключительно 
ядром захвата дампа и в противном случае не используется во время нормальной работы системы. 
Некоторые архитектуры, включая x86 и ppc64, требуют небольшую часть оперативной памяти с фиксированным 
положением для загрузки ядра независимо от того, где оно загружено; в этом случае kexec создает копию этой 
части оперативной памяти, чтобы она также была доступна для ядра захвата дампа. Размер 
зарезервированной части ОЗУ задается через параметр загрузки ядра ``crashkernel`` (я использовал 128 Мб), а утилита командной строки 
kexec используется после начальной загрузки основного ядра для предварительной загрузки образа ядра захвата 
дампа и связанного с ним образа ``initrd`` в зарезервированную часть оперативной памяти.
Анализ дампа производиться либо через ``gdb`` за описаным к нему сценарием либо через схожую к нему утилиту ``crash``, которая
используется в основном для ``RHEL``, но также может быть установлена на ``debian`` и с переменным успехом на ``archlinux``.


Работа с KGDB
-----   
Для начало в иследуемом ядре необходимо предусмотреть поддержку данного способа отладки, необходимо что бы следующие конфиги 
были активны:

.. code-block:: C

    CONFIG_FRAME_POINTER=y
    CONFIG_KGDB=y
    CONFIG_KGDB_SERIAL_CONSOLE=y

Также нужно передать название интерфейса по которому будет проводиться свзяь:

 .. code-block:: C
    
    echo ttyS0 >/sys/module/kgdboc/parameters/kgdboc

Если речь идёт про встроенные системы то данный параметр необходимо определить в загрузчике, к примеру для Uboot:
 
 .. code-block:: C
 
    sete bootargs console=ttyS1,115200 root=/dev/nfs rw ip=dhcp gdb

На основную систему, с которой будут проводиться исследования, нужно перенести образ ядра с подопытной системы.
Следующим шагом необходимо открыть ``gdb`` с аргументов в виде этого самого образа ядра исследуемой системы. Дальше 
нужно подключиться по нужному интерфейсу, который был сконфигурирован для связи между двумя системами:

 .. code-block:: C

    (gdb) target remote /dev/ttyS0
    Remote debugging using /dev/ttyS0

После этих операций у нас установлена связь между двумя системами посредством ``kgdb``, которая позволяет в реальном времене
проводить отладку средств ядра, к примеру поставить breakpoint:

 .. code-block:: C

    (gdb) b panic
    Breakpoint 1 at 0xc0016b18: file kernel/panic.c, line 74.
    

Отладка модуля ядра средствами GDB
----- 

Аналогично к предыдущему случаю, можно использовать gdb для отладки модулей, но теперь уже не требуется две системы для этого.
На одной системе можно запускать модули и фактически одновременно проводить их отладку. 
gdb может быть очень полезен для просмотра внутренних систем. Умелое использование отладчика на этом уровне 
требует некоторой уверенности в командах gdb, некоторого понимания кода сборки для целевой платформы и способности 
сопоставлять исходный код и оптимизированную сборку.

Необходимо загрузить модуль в ядро перед началом его отладки и вычитать его его ``.text .data .bss`` разделы.
Обычно это делается утилитой ``cat`` в директории загруженных модулей. ``.text``  раздел содержит исполняемый код для модуля. 
Остальные два раздела содержат переменные модуля. Любая переменная, которая не инициализируется во время компиляции,
заканчивается в ``.bss``, тогда как переменные, которые инициализируются, попадают в ``.data``. 

``gdb`` должен принимать два аргумента: испольняемый файл ядра и ``kernel core``. Обычно команда запуска 
выглядит так 

 .. code-block:: C
 
  gdb /usr/src/linux/vmlinux /proc/kcore

После открытия отладчика ему стоит передать ранее прочитаные значения с трёх разделом:

 .. code-block:: C

    (gdb) add-symbol-file /home/maks/Documents/modules/.build/hivemod.ko 0xffffffffc0835000 -s .data 0xffffffffc0837000 -s .bss 0xffffffffc0837480
    add symbol table from file "/home/maks/Documents/modules/.build/hivemod.ko" at
      .text_addr = 0xc0835000
      .data_addr = 0xc0837000
      .bss_addr = 0xc0837480
    (y or n) y
    Reading symbols from /home/maks/Documents/modules/.build/hivemod.ko...
    (gdb) 

Теперь отладчик готов к работе, он имеет много функций, такие так установка точек останова, печать переменных и т.д. 
К примеру, выведем информацию о некоторых переменных с модуля:

 .. code-block:: C

    (gdb) info variables 
    All defined variables:

    File ./include/linux/fs.h:
    2885:	static const char * constkernel_read_file_str[9];

    File /home/maks/Documents/modules/.build/hivemod.c:
    49:	struct dentry *add_entry;
    49:	struct dentry *dfs;
    89:	dev_t hive_dev;
    50:	struct debugfs_blob_wrapper *myblob;
    47:	struct rb_root mytree;
    49:	struct dentry *parent_debug;
    49:	struct dentry *sum_entry;
    49:	struct dentry *test_entry;
    16:	static const char __UNIQUE_ID_author25[17];
    --Type <RET> for more, q to quit, c to continue without paging-- 
    87:	static const char __UNIQUE_ID_buffsize33[68];
    86:	static const char __UNIQUE_ID_buffsizetype32[22];
    15:	static const char __UNIQUE_ID_description24[34];
    81:	static const char __UNIQUE_ID_devname29[53];
    80:	static const char __UNIQUE_ID_devnametype28[23];
    18:	static const char __UNIQUE_ID_license27[21];
    84:	static const char __UNIQUE_ID_major31[62];
    83:	static const char __UNIQUE_ID_majortype30[19];
    17:	static const char __UNIQUE_ID_version26[12];
    86:	static const struct kernel_param __param_buffsize;
    80:	static const struct kernel_param __param_devname;
    83:	static const struct kernel_param __param_major;
    86:	static const char __param_str_buffsize[9];
    80:	static const char __param_str_devname[8];
    83:	static const char __param_str_major[6];


Когда происходит печатать данных из под ``gdb``, ядро все еще работает, и различные элементы данных имеют разные значения в 
разное время; ``gdb``, однако, оптимизирует доступ к файлу ядра, кэшируя данные, которые уже были прочитаны. 
Если попытаться взглянуть на переменную еще раз, то на выходе будет тот же ответ, что и раньше. 
Кэширование значений является правильным поведением для обычных
файлов ядра, но неудобно, когда используется «динамический» образ ядра.


Анализ краш-дампа с помощью утилиты crash
----- 

Утилита ``crash`` является очень удобным инструментом для анализа дампом систем, которые потерпели крах.

Перед началом работы необходимо удостовериться, что активны следующие конфиги:

.. code-block:: C

    CONFIG_KEXEC=y
    CONFIG_CRASH_DUMP=y
    CONFIG_PROC_VMCORE=y
    CONFIG_DEBUG_INFO=y
    CONFIG_MAGIC_SYSRQ=y
    CONFIG_RELOCATABLE=y

Для демонстрации 
необходимо "убить" подопытную систему, что бы произошло срабатывание утилиты ``kexec`` и запись дампа. 

Для этой цели можно использовать две команды ``SysRq``, которые позволят в "легальный" способ заставить систему уйти в принужденную 
перезагрузку и записать дамп. Первая команда разрешает все функции ``SysRq``, а вторая - пока неизвестным нам способом вызывает ошибку 
работы ядра и автоматически происходит запись дампа.


.. code-block:: C

    echo 1 > /proc/sys/kernel/sysrq
    echo t > /proc/sysrq-trigger
    
Таким образом, произойдет перезагрузка системы и в директории ``/var/crash`` будут доступна запись дампа памяти ядра 
на момент его краха. Открываем утилиту:

.. code-block:: C

         PANIC: "SysRq : Trigger a crash"
         PID: 3193
     COMMAND: "bash"
        TASK: ffff88007d58c040  [THREAD_INFO: ffff88007b6fc000]
         CPU: 0
       STATE: TASK_RUNNING (SYSRQ)

С первой доступной информацией про состояние и характеристики системы можно увидеть что процес с PID 3193 был последним 
активным процесом перед полным крахом системы. Этот процес был скриптом bash и вызвал ``kernel panic``, который именуется 
в системе как ``SysRq : Trigger a crash``.
Следующим шагом проанализируем трассировки стека, которые представляет собой отчет об активных кадрах стека в 
определенный момент времени во время выполнения программы. Делается это путём применения команды ``bt`` (backtrace):
 
 .. code-block:: C
 
        PID: 3193   TASK: ffff88007d58c040  CPU: 0   COMMAND: "bash"
     #0 [ffff88007b6ff9b0] machine_kexec at ffffffff8104111b
     #1 [ffff88007b6ffa10] crash_kexec at ffffffff810d6932
     #2 [ffff88007b6ffae0] oops_end at ffffffff8155e310
     #3 [ffff88007b6ffb10] no_context at ffffffff810546bb
     #4 [ffff88007b6ffb60] __bad_area_nosemaphore at ffffffff81054945
     #5 [ffff88007b6ffbb0] bad_area at ffffffff81054a6e
     #6 [ffff88007b6ffbe0] __do_page_fault at ffffffff8105526e
     #7 [ffff88007b6ffd00] do_page_fault at ffffffff815602ce
     #8 [ffff88007b6ffd30] page_fault at ffffffff8155d265
        [exception RIP: sysrq_handle_crash+22]
        RIP: ffffffff81369686  RSP: ffff88007b6ffde8  RFLAGS: 00010096
        RAX: ffffffff81369670  RBX: 0000000000000063  RCX: 0000000000000000
        RDX: 0000000000000000  RSI: 0000000000000000  RDI: 0000000000000063
        RBP: ffff88007b6ffde8   R8: 0000000000000000   R9: 0000000000000000
        R10: 0000000000000001  R11: 0000000000000246  R12: 0000000000000000
        R13: ffffffff81b15800  R14: 0000000000000282  R15: 0000000000000001
        ORIG_RAX: ffffffffffffffff  CS: 0010  SS: 0018

Отчет идет с низу в верх. Как видно, после исключения происходит ошибка страницы памяти, обработка конфликтной ситуации и последние строки показывают,
что идёт вызов функции ``crash_kexec``, которая положила началу формирования дампа. 
 
Исключение вызвала функция ``sysrq_handle_crash`` со сдвигом 22, тоесть на 22 позиции от момента начала описания функции. С мопомщью
того же ``crash`` посмотрим что происходит внути этой функции с помощью команды ``dis``.

 .. code-block:: C
  
  crash> dis sysrq_handle_crash+22
  0xffffffff81369686 <sysrq_handle_crash+22>:     movb   $0x1,0x0
  crash> dis sysrq_handle_crash
  0xffffffff81369670 <sysrq_handle_crash>:        push   %rbp
  0xffffffff81369671 <sysrq_handle_crash+1>:      mov    %rsp,%rbp
  0xffffffff81369674 <sysrq_handle_crash+4>:      nopl   0x0(%rax,%rax,1)
  0xffffffff81369679 <sysrq_handle_crash+9>:      movl   $0x1,0x744c2d(%rip)        # 0xffffffff81aae2b0 <panic_on_oops>
  0xffffffff81369683 <sysrq_handle_crash+19>:     sfence 
  0xffffffff81369686 <sysrq_handle_crash+22>:     movb   $0x1,0x0
  0xffffffff8136968e <sysrq_handle_crash+30>:     leaveq 
  0xffffffff8136968f <sysrq_handle_crash+31>:     retq
 
Если указать смещение, то сразу будет показана соответствующая строка, а если без смещения - будет показан весь дизассемблер функции.
И как можно увидеть, происходит попытка разыменования нулевого указателя, что категорически запрещено. Это и крашит систему. 
Посмотрим реализацию на языке С:

.. code-block:: C

    static void sysrq_handle_crash(int key)
    {
      char *killer = NULL;

      /* we need to release the RCU read lock here,
       * otherwise we get an annoying
       * 'BUG: sleeping function called from invalid context'
       * complaint from the kernel before the panic.
       */
      rcu_read_unlock();
      panic_on_oops = 1;	/* force panic */
      wmb();
      *killer = 1;
    }

Как видно, указатель ``killer`` изначально задан как NULL, в конце происходит попытка его разыименования и запись, что вызывает ошибку 
страницы памяти и другие последствия. 
Более подробно про ``crash`` можно почитать `здесь <https://people.redhat.com/anderson/crash_whitepaper/>`__ , очень много чего можно найти.


Работа с DebugFS  
-----

В наведенном ниже фрагменте приводиться пример работы с ``DebugFs``. Проделан процесс создания директория с отладочной
информацией. Опробовано создание файлов и операций к ним, численных переменных, которые используються в файловых операциях,
механизм работы с фрагментами памяти или ``blob`` (в данном случае - текстовый массив). 
Важно отметить, что согласно документации - такие фрагменты доступны только для чтения, попытки записи приводят к ошибках и непредсказуемое 
поведение

 .. code-block:: C

    parent_debug = debugfs_create_dir("hive", NULL);

      if (-ENODEV == parent_debug) {
        return -ENOMEM;
      }

      add_entry = debugfs_create_file("add", 0222, parent_debug, NULL, &add_fops);
          if (add_entry == NULL) {
              // Abort module load.
              printk(KERN_ALERT "debugfs_example: failed to create\n");
              return -1;
          }

      test_entry = debugfs_create_blob("test", 0777, parent_debug, myblob);

      if (test_entry == NULL) {
        MOD_DEBUG(KERN_DEBUG, "DebugFS file NOT created");
        return -EINVAL;
      }

      myblob = kmalloc(sizeof(struct debugfs_blob_wrapper), GFP_KERNEL);

      myblob->data = (void *)buf;
      myblob->size = buffsize/2;

      if (myblob == NULL) {
        return -ENOMEM;
      }
      // fill the rest

      sum_entry = debugfs_create_u32("sum", 0777, parent_debug, &sum);
      if (sum_entry == NULL) {
              // Abort module load.
              printk(KERN_ALERT "debugfs_example: filed to create\n");
              return -1;
         }

      MOD_DEBUG(KERN_DEBUG, "DebugFS file created"); 


Вывод 
----- 

Дебаг через ``printk()`` наше всё!


