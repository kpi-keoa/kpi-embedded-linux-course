=============================================
Лабораторная работа №3
=============================================

Цели: 
	- Изучить принципы работы со списками в ядре, потоки и механизмы синхронизации
	- Написать модуль ядра, который, содержит переменную, запускает M потоков на одновременное выполнение
	- Каждый поток инкрементирует переменную N раз, кладет значение переменной в список и завершается
	- При выгрузке модуль выводит значение переменной и содержимое списка
	- Использовать параметры модуля для задания инкремента N и количества потоков M
	- Для переменной, списка, потоков использовать динамическую аллокацию. Переменную передавать в поток по ссылке аргументом
	- Проверить на разных платформах. Продемонстрировать, что без синхронизации итоговое значение глобальной переменной неправильное
	- Реализовать функции lock() и unlock() с использованием атомарных операций ядра.
	- Защитить доступ к шареным элементам.
	- Необходимо учитывать и корректно отрабатывать возможные ошибки.

Теоретические сведения 
-----

Параллелизм – это ситуация, когда одновременно выполняется два или более процесса, которые могут потенциально взаимодействовать друг с другом (например, использовать один и тот же набор ресурсов). 
Параллелизм может встречаться на однопроцессорных рабочих станциях, где несколько потоков используют один и тот же процессор, вытесняя друг друга и создавая ситуацию гонки. Вытеснением называется прозрачное совместное использование процессора путем временной приостановки одного потока для обеспечения возможности выполнения другого. 
Ситуация гонки - это ситуация, когда два или более потока управляют одними и теми же данными и результат зависит от порядка выполнения. 
В случае однопроцессорной системы параллелизм создаётся механизмом вытеснения. 

Для решения проблемы ситуаций гонки было разработана концепция критической секции. Критическая секция - это часть кода, защищенная от одновременного доступа. Эта часть кода может управлять данными и службами общего пользования (например, периферийным оборудованием). 
Критические секции работают по принципу взаимного исключения (когда поток находится в критической секции, вход любых других потоков не допускается).

`Источник <https://www.ibm.com/developerworks/ru/library/l-linux-synchronization/index.html>`__ 

Некоторые методы синхронизации Linux 
-----

Атомарные операции 
-----
Простейшим средством синхронизации ядра Linux являются атомарные операции. Атомарность означает, что критическая секция содержится внутри функции API. Необходимость в блокировке отсутствует, поскольку она подразумевается в вызове. 
Учитывая, что язык C не может гарантировать атомарности операций, Linux использует для этого архитектуру более низкого уровня.
Атомарные операторы идеальны для ситуаций, в которых защищаемые данные просты, например, как счетчик.

Пример простых атомарных операций:

	.. code-block:: C
			val = atomic_read( &my_counter );
		        atomic_add( 1, &my_counter );
		        atomic_inc( &my_counter );
		        atomic_sub( 1, &my_counter );
		        atomic_dec( &my_counter );

Взаимные блокировки 
-----
Взаимные блокировки (спинлоки) предоставляют особый способ обеспечения взаимных исключений посредством циклов активного ожидания блокировок.
Если блокировка доступна, она захватывается, взаимно исключающее действие выполняется, и блокировка снимается.
.Если блокировка недоступна, поток переводится в состояние активного ожидания блокировки, пока она не освободится.

Создание и инициализация взаимных блокировок:

	.. code-block:: C

			spinlock_t my_spinlock = SPIN_LOCK_UNLOCKED;
			spin_lock( &my_spinlock );
			//critical section
			spin_unlock( &my_spinlock );

Взаимные блокировки чтения и записи 		
-----
В большинстве случаев доступ к данным характеризуется большим числом читающих процессов и меньшим числом пишущих (доступ к данным для чтения более распространен, чем доступ для записи). 
Для поддержки такой модели были созданы взаимные блокировки чтения/записи.
В этой модели интересно то, что одновременно разрешается доступ к данным нескольким операциям считывания и только одной операции записи.
Если блокировка установлена пишущим процессом, чтение в критической секции не допускается. Если блокировка установлена читающим процессом, в критической секции допускается несколько операций чтения.

Функции взаимной блокировки чтения и записи:

	.. code-block:: C

			rwlock_t my_rwlock;
		        rwlock_init( &my_rwlock );
		        write_lock( &my_rwlock );
			//critical section write+read
		        write_unlock( &my_rwlock );

		        read_lock( &my_rwlock );
			//critical section only read
		        read_unlock( &my_rwlock );

Выполнение
-----
Результатом лабораторной работы представлен модуль ядра, функция которого описана выше в разделе **Цели**. 
Модуль имеет возможность запускать потоки внутри ядра и завершаться по завершению. Кол-во потоков задаётся через параметры.
Целью запуска потоков есть проверка корректности использования шаренного ресурса между идентичными потоками.
В данном случае задачей является итерация шаренной между потоками **unsigned long long cnt** переменной от 0 до **Ntimes**, где **Ntimes** задаётся параметром при установке.
Результат каждого потока в ввиде математической суммы складывается в созданный ранее циклический связанный список, API которого находится в **linux/list.h**.
В итогам работы модуля, а именно прохода всех потоков, **__init** функция модуля оставляет за собой хранить результаты вычислений для каждого потока в динамической памяти 
в структуре связанного спика.

Для получения результата и оценки корректности выполнения арифметической операции необходимо выгрузить модуль.
Соотствующие результаты, а именно вывод содержимого списка, будут выведены в логи ядра.
  
Так как связанный список также является шаренным ресурсом его необходимо защитить блокировкой записи.

Также для сравнения результатов операции над инкрементом шареного счётчика модуль был запущен с блокировкой в месте где проводится эта операция, которая и считается критической секцией.
Для блокировки этой секции был использован механизм синхронизации ` Взаимные блокировки ` - spinlock. 

	.. code-block:: C

		for (unsigned long long i = 0; i < Ntimes; i++) {
			spin_lock( &spinlock );
			(*local_cnt)++;
			spin_unlock( &spinlock );
		}


Базовые операции для работы с модулем
-----
	.. code-block:: C
		
			# make [clean]
			# insmod src/firstmod.ko Mthreads=2 Ntimes=1000xx 
			# rmmod firstmod 
			# dmesg -k | tail -20 


Интерпретация результатов для **x86_64**. 
-----

.. code-block:: C

	Mthreads=9 
	Ntimes=10000000 

**Логи ядра c синхронизацией**

.. code-block:: C

	[12945.461802] Node stored: [90000000]
	[12945.461804] Node stored: [89755133]
	[12945.461804] Node stored: [89662130]
	[12945.461805] Node stored: [89605839]
	[12945.461805] Node stored: [88729509]
	[12945.461806] Node stored: [88557387]
	[12945.461807] Node stored: [88378379]
	[12945.461807] Node stored: [85516721]
	[12945.461808] Node stored: [83038250]

**Логи ядра без синхронизации**

.. code-block:: C

	[13114.596569] Node stored: [10587105]
	[13114.596570] Node stored: [9622479]
	[13114.596571] Node stored: [8654736]
	[13114.596571] Node stored: [10647202]
	[13114.596571] Node stored: [5848129]
	[13114.596572] Node stored: [7687386]
	[13114.596572] Node stored: [7282932]
	[13114.596573] Node stored: [4745606]
	[13114.596573] Node stored: [3441090]


Интерпретация результатов для **armhf | BeagleBone**. 
------

**Логи ядра c синхронизацией**

.. code-block:: C

	[ 1182.923069] Node stored: [90000000]
	[ 1182.923087] Node stored: [89996068]
	[ 1182.923093] Node stored: [89991621]
	[ 1182.923098] Node stored: [89986954]
	[ 1182.923103] Node stored: [89983195]
	[ 1182.923108] Node stored: [89974574]
	[ 1182.923113] Node stored: [89963053]
	[ 1182.923119] Node stored: [89953384]
	[ 1182.923124] Node stored: [89946959]

**Логи ядра без синхронизации**

.. code-block:: C

	[ 1354.676890] Node stored: [13322759]
	[ 1354.676908] Node stored: [12621223]
	[ 1354.676914] Node stored: [11297870]
	[ 1354.676919] Node stored: [10857130]
	[ 1354.676924] Node stored: [10000000]
	[ 1354.676929] Node stored: [13002235]
	[ 1354.676934] Node stored: [12179975]
	[ 1354.676940] Node stored: [11739069]
	[ 1354.676945] Node stored: [10418125]


Выводы
------
Было протестировано работу kthreads для разных архитектур, проанализировано работу с/без использованием методов синхронизации. 
С результатов видно, что без синхронизации потоки стремятся перехватить общий адресс, в которой хранится переменная.Данная процедура не есть атомарная, в результате чего мы получаем абсолютно неожиданный разультат в вычислениях.
С синхронизацией дела обстоят намного лучше: 90000000-89946959=53041 примерно такая разница между первым и последним записанным потоком в список. Видно, что первый поток имеет наибольшую вероятность того, что результат будет правильный.
Так же было обнаружено, что в случае незащищенности списка как шаренного ресурса при операции добавления узла и пр. возможно возникновение ошибок обращения к памяти вроде **Segmentation Fault** и пр.
 

